{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_tmp = pd.read_csv('../data/predictions.csv')\n",
    "# pred = pd.DataFrame(pred_tmp['visitorid'])\n",
    "# pred[(pred['visitorid'].isin(events['visitorid'])==True)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENTS: 2756101\n",
      "Train rows are: 1896804\n",
      "Test rows are: 553373\n",
      "Filtered out Interactions are: 305924\n",
      "CATEGORIES: 1669\n"
     ]
    }
   ],
   "source": [
    "def get_events(filter_flag=False):    \n",
    "    events = pd.read_csv('../data/events.csv')\n",
    "    if(filter_flag==True):\n",
    "        events = events[events['event']=='transaction']\n",
    "    else:\n",
    "        events = events\n",
    "    print(\"EVENTS:\",events.shape[0])\n",
    "    return events\n",
    "\n",
    "def get_categories():\n",
    "    category_tree = pd.read_csv('../data/category_tree.csv')\n",
    "    category_tree[category_tree['parentid'].isnull()==True] = 0\n",
    "    category_tree['parentid'] = category_tree['parentid'].apply(lambda x:round(x))\n",
    "    print(\"CATEGORIES:\",category_tree.shape[0])\n",
    "    return category_tree\n",
    "\n",
    "def get_unique_list(df, user_column):\n",
    "    return np.sort(df[user_column].unique())\n",
    "\n",
    "def make_splits(df):\n",
    "    #First convert to datetime format\n",
    "    df = df.assign(timestamp=pd.Series(datetime.datetime.fromtimestamp(i/1000).date() for i in df.timestamp))\n",
    "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    #Train\n",
    "    train = df[(df.timestamp < datetime.datetime.strptime('2015-08-01', '%Y-%m-%d').date())]\n",
    "    #Eval\n",
    "    test = df[\n",
    "        (df.timestamp < datetime.datetime.strptime('2015-09-01', '%Y-%m-%d').date())\n",
    "        &         (df.timestamp > datetime.datetime.strptime('2015-07-31', '%Y-%m-%d').date())\n",
    "    ]\n",
    "    #Filtered\n",
    "    fltr = df[\n",
    "        (df.timestamp > datetime.datetime.strptime('2015-08-31', '%Y-%m-%d').date())\n",
    "    ]\n",
    "    print(\"Train rows are:\",train.shape[0])\n",
    "    print(\"Test rows are:\",test.shape[0])\n",
    "    print(\"Filtered out Interactions are:\",fltr.shape[0])\n",
    "    \n",
    "    return train,test\n",
    "\n",
    "def get_predictors():\n",
    "    pred = pd.read_csv('../data/predictions.csv')\n",
    "\n",
    "events = get_events(False)\n",
    "train_events,test_events = make_splits(events)\n",
    "category_tree = get_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITEMS: 20275902\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def get_items(events):\n",
    "    items1 = pd.read_csv('../data/item_properties_part1.csv')\n",
    "    items2 = pd.read_csv('../data/item_properties_part2.csv')\n",
    "    items = pd.concat([items1, items2])\n",
    "    print(\"ITEMS:\",items.shape[0])\n",
    "    return items\n",
    "\n",
    "items_df = get_items(events)\n",
    "items = get_unique_list(items_df,'itemid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = get_unique_list(events,'visitorid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events: 2500516\n",
      "Train Events: 1725857\n",
      "Test Events: 499399\n",
      "Items: 10180153\n"
     ]
    }
   ],
   "source": [
    "#remove items that are not in events\n",
    "#remove event items that are not in items\n",
    "items_df = items_df[items_df.itemid.isin(events.itemid)==True]\n",
    "events = events[events.itemid.isin(items_df.itemid)==True]\n",
    "print(\"Events:\",events.shape[0])\n",
    "train_events = train_events[train_events.itemid.isin(items_df.itemid)==True]\n",
    "test_events = test_events[test_events.itemid.isin(items_df.itemid)==True]\n",
    "print(\"Train Events:\",train_events.shape[0])\n",
    "print(\"Test Events:\",test_events.shape[0])\n",
    "print(\"Items:\",items_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396660"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_item_feature_interaction(items_df, category_tree_df):\n",
    "    items_to_cat = items_df[(items_df.property == 'categoryid')][['itemid','value']].drop_duplicates()\n",
    "    items_to_cat['value'] = items_to_cat['value'].astype(int)\n",
    "    item_feature_df = pd.merge(items_to_cat, category_tree_df.rename(columns={'categoryid':'value'}), on='value',  how='left')\n",
    "\n",
    "    item_category_df = item_feature_df[[\"itemid\", \"value\"]].rename(columns = {\"value\" : \"feature\"})\n",
    "    item_category_df[\"feature_count\"] = 1 # adding weight to category feature\n",
    "    item_parent_df = item_feature_df[[\"itemid\", \"parentid\"]].rename(columns = {\"parentid\" : \"feature\"})\n",
    "    item_parent_df[\"feature_count\"] = 1 # adding weight to department feature\n",
    "\n",
    "    item_feature_df_sub = pd.concat([item_category_df, item_parent_df], ignore_index=True)\n",
    "\n",
    "    # saving some memory\n",
    "    del item_feature_df\n",
    "    del item_category_df\n",
    "    del item_parent_df\n",
    "\n",
    "    # grouping for summing over feature_count\n",
    "    item_feature_df = item_feature_df_sub.groupby([\"itemid\", \"feature\"], as_index = False)[\"feature_count\"].sum()\n",
    "    return item_feature_df\n",
    "\n",
    "item_to_feature = get_item_feature_interaction(items_df, category_tree)\n",
    "item_to_feature.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_mappings(user_list, item_list):\n",
    "    \"\"\"\n",
    "    \n",
    "    Create id mappings to convert user_id, item_id, and feature_id\n",
    "    \n",
    "    \"\"\"\n",
    "    user_to_index_mapping = {}\n",
    "    index_to_user_mapping = {}\n",
    "    for user_index, user_id in enumerate(user_list):\n",
    "        user_to_index_mapping[user_id] = user_index\n",
    "        index_to_user_mapping[user_index] = user_id\n",
    "        \n",
    "    item_to_index_mapping = {}\n",
    "    index_to_item_mapping = {}\n",
    "    for item_index, item_id in enumerate(item_list):\n",
    "        item_to_index_mapping[item_id] = item_index\n",
    "        index_to_item_mapping[item_index] = item_id\n",
    "                \n",
    "    return user_to_index_mapping, index_to_user_mapping, \\\n",
    "           item_to_index_mapping, index_to_item_mapping\n",
    "\n",
    "# generate mapping, LightFM library can't read other than (integer) index\n",
    "user_to_index_mapping, \\\n",
    "index_to_user_mapping, \\\n",
    "item_to_index_mapping, \\\n",
    "index_to_item_mapping = id_mappings(users, items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awaiskaleem/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitorid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>item_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>61396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>139394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>164941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>226353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>222422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visitorid  itemid  item_count\n",
       "0          5   61396           1\n",
       "1          7  139394           1\n",
       "2          7  164941           1\n",
       "3          7  226353           1\n",
       "4          9  222422           1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_user_product_interaction(events):\n",
    "    \n",
    "    # creating a dataframe consists of TWO columns user_id, and product_name (product bought by the user) for the train data\n",
    "    user_to_item_df = events[['visitorid','itemid']]\n",
    "    user_to_item_df[\"item_count\"] = 1\n",
    "    user_to_item_rating = user_to_item_df.groupby([\"visitorid\", \"itemid\"], as_index = False)[\"item_count\"].sum()\n",
    "    return user_to_item_rating\n",
    "\n",
    "# convert to the user, item, feature lists into indexes.\n",
    "# interaction matrices can only consume indexes\n",
    "user_to_item_train = get_user_product_interaction(train_events)\n",
    "user_to_item_test = get_user_product_interaction(test_events)\n",
    "user_to_item_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>938.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>573.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemid  feature  feature_count\n",
       "0       3    938.0              1\n",
       "1       3   1171.0              1\n",
       "2       4   1038.0              1\n",
       "3       4   1174.0              1\n",
       "4       6    573.0              1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_to_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interaction_matrix(df, df_column_as_row, df_column_as_col, df_column_as_value, row_indexing_map, \n",
    "                          col_indexing_map):\n",
    "    \n",
    "    row = df[df_column_as_row].apply(lambda x: row_indexing_map[x]).values\n",
    "    col = df[df_column_as_col].apply(lambda x: col_indexing_map[x]).values\n",
    "    value = df[df_column_as_value].values\n",
    "    \n",
    "    return coo_matrix((value, (row, col)), shape = (len(row_indexing_map), len(col_indexing_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix # for constructing sparse matrix\n",
    "# generate user_item_interaction_matrix for train data\n",
    "train_user_to_item_interaction = get_interaction_matrix(user_to_item_train\n",
    "                                                  , \"visitorid\"\n",
    "                                                  , \"itemid\"\n",
    "                                                  , \"item_count\"\n",
    "                                                  , user_to_index_mapping\n",
    "                                                  , item_to_index_mapping)\n",
    "\n",
    "test_user_to_item_interaction = get_interaction_matrix(user_to_item_test\n",
    "                                                  , \"visitorid\"\n",
    "                                                  , \"itemid\"\n",
    "                                                  , \"item_count\"\n",
    "                                                  , user_to_index_mapping\n",
    "                                                  , item_to_index_mapping)\n",
    "\n",
    "# generate item_to_feature interaction\n",
    "item_to_feature_interaction = get_interaction_matrix(item_to_feature\n",
    "                                                           , \"itemid\"\n",
    "                                                           , \"feature\"\n",
    "                                                           , \"feature_count\"\n",
    "                                                           , item_to_index_mapping\n",
    "                                                           , index_to_item_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1407580, 417053) (1407580, 417053)\n"
     ]
    }
   ],
   "source": [
    "assert(test_user_to_item_interaction.shape[0]==train_user_to_item_interaction.shape[0])\n",
    "print(test_user_to_item_interaction.shape,train_user_to_item_interaction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awaiskaleem/anaconda3/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "# lightfm \n",
    "from lightfm import LightFM # model\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "\n",
    "# initialising model with warp loss function\n",
    "model_without_features = LightFM(loss = \"warp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken = 11179.65 seconds\n",
      "average AUC without adding item-feature interaction = 0.88\n",
      "average Precision without adding item-feature interaction = 0.00\n",
      "average Recall without adding item-feature interaction = 0.01\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# fitting into user to product interaction matrix only / pure collaborative filtering factor\n",
    "\n",
    "start = time.time()\n",
    "#===================\n",
    "\n",
    "model_without_features.fit(train_user_to_item_interaction,\n",
    "          user_features=None, \n",
    "          item_features=None, \n",
    "          sample_weight=None, \n",
    "          epochs=1, \n",
    "          num_threads=4,\n",
    "          verbose=False)\n",
    "\n",
    "#===================\n",
    "end = time.time()\n",
    "print(\"time taken = {0:.{1}f} seconds\".format(end - start, 2))\n",
    "\n",
    "# auc metric score (ranging from 0 to 1)\n",
    "\n",
    "start = time.time()\n",
    "#===================\n",
    "\n",
    "auc_without_features = auc_score(model = model_without_features, \n",
    "                        test_interactions = test_user_to_item_interaction,\n",
    "                        num_threads = 4, check_intersections = False)\n",
    "\n",
    "precision_without_features = precision_at_k(model = model_without_features, \n",
    "                        test_interactions = test_user_to_item_interaction,\n",
    "                        num_threads = 4, check_intersections = False)\n",
    "\n",
    "recall_without_features = recall_at_k(model = model_without_features, \n",
    "                        test_interactions = test_user_to_item_interaction,\n",
    "                        num_threads = 4, check_intersections = False)\n",
    "#===================\n",
    "end = time.time()\n",
    "print(\"time taken = {0:.{1}f} seconds\".format(end - start, 2))\n",
    "print(\"average AUC without adding item-feature interaction = {0:.{1}f}\".format(auc_without_features.mean(), 2))\n",
    "print(\"average Precision without adding item-feature interaction = {0:.{1}f}\".format(precision_without_features.mean(), 2))\n",
    "print(\"average Recall without adding item-feature interaction = {0:.{1}f}\".format(recall_without_features.mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average AUC without adding item-feature interaction = 0.85\n",
      "average Precision without adding item-feature interaction = 0.00\n",
      "average Recall without adding item-feature interaction = 0.00\n"
     ]
    }
   ],
   "source": [
    "# initialising model with warp loss function\n",
    "model_with_features = LightFM(loss = \"warp\")\n",
    "\n",
    "# fitting the model with hybrid collaborative filtering + content based (product + features)\n",
    "start = time.time()\n",
    "#===================\n",
    "\n",
    "\n",
    "model_with_features.fit(train_user_to_item_interaction,\n",
    "          user_features=None, \n",
    "          item_features=item_to_feature_interaction, \n",
    "          sample_weight=None, \n",
    "          epochs=1, \n",
    "          num_threads=4,\n",
    "          verbose=False)\n",
    "\n",
    "#===================\n",
    "end = time.time()\n",
    "print(\"time taken = {0:.{1}f} seconds\".format(end - start, 2))\n",
    "\n",
    "start = time.time()\n",
    "#===================\n",
    "auc_with_features = auc_score(model = model_with_features, \n",
    "                        test_interactions = test_user_to_item_interaction,\n",
    "                        item_features = item_to_feature_interaction,\n",
    "                        num_threads = 4, check_intersections=False)\n",
    "\n",
    "precision_with_features = precision_at_k(model = model_with_features, \n",
    "                        test_interactions = test_user_to_item_interaction,\n",
    "                        num_threads = 4, check_intersections = False)\n",
    "\n",
    "recall_with_features = recall_at_k(model = model_with_features, \n",
    "                        test_interactions = test_user_to_item_interaction,\n",
    "                        num_threads = 4, check_intersections = False)\n",
    "#===================\n",
    "end = time.time()\n",
    "print(\"time taken = {0:.{1}f} seconds\".format(end - start, 2))\n",
    "\n",
    "print(\"average AUC without adding item-feature interaction = {0:.{1}f}\".format(auc_with_features.mean(), 2))\n",
    "print(\"average Precision without adding item-feature interaction = {0:.{1}f}\".format(precision_with_features.mean(), 2))\n",
    "print(\"average Recall without adding item-feature interaction = {0:.{1}f}\".format(recall_with_features.mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_train_test(train, test):\n",
    "    \"\"\"\n",
    "    \n",
    "    test set is the more recent rating/number_of_order of users.\n",
    "    train set is the previous rating/number_of_order of users.\n",
    "    non-zero value in the test set will replace the elements in \n",
    "    the train set matrices\n",
    "\n",
    "    \"\"\"\n",
    "    # initialising train dict\n",
    "    train_dict = {}\n",
    "    for train_row, train_col, train_data in zip(train.row, train.col, train.data):\n",
    "        train_dict[(train_row, train_col)] = train_data\n",
    "        \n",
    "    # replacing with the test set\n",
    "    \n",
    "    for test_row, test_col, test_data in zip(test.row, test.col, test.data):\n",
    "        train_dict[(test_row, test_col)] = max(test_data, train_dict.get((test_row, test_col), 0))\n",
    "        \n",
    "    \n",
    "    # converting to the row\n",
    "    row_element = []\n",
    "    col_element = []\n",
    "    data_element = []\n",
    "    for row, col in train_dict:\n",
    "        row_element.append(row)\n",
    "        col_element.append(col)\n",
    "        data_element.append(train_dict[(row, col)])\n",
    "        \n",
    "    # converting to np array\n",
    "    \n",
    "    row_element = np.array(row_element)\n",
    "    col_element = np.array(col_element)\n",
    "    data_element = np.array(data_element)\n",
    "    \n",
    "    return coo_matrix((data_element, (row_element, col_element)), shape = (train.shape[0], train.shape[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
